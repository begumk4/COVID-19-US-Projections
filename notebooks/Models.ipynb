{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the CSSE Daily Data for COVID 19:\n",
    "https://github.com/CSSEGISandData/COVID-19\n",
    "\n",
    "Using the code provided by Prof. James Sharpnack\n",
    "https://github.com/jsharpna/CovidResponse208\n",
    "\n",
    "The population dataset is from the 2019 census\n",
    "\n",
    "and \n",
    "## Parsing the social Distancing data from Safegraph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "TensorFlow version: 2.1.0\nEager execution: True\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotnine as p9\n",
    "import mizani\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Sequential, losses\n",
    "\n",
    "from scipy.stats import nbinom\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.__version__))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
    "tf.keras.backend.set_floatx('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(3573, 4)\n(3573, 1)\n"
    }
   ],
   "source": [
    "X_tr = pd.read_csv('../data/X_tr.csv')   \n",
    "y_tr = pd.read_csv('../data/y_tr.csv') \n",
    "print(X_tr.shape)\n",
    "print(y_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([y_tr['Incident_Rate'] < 0.5].shape)\n",
    "X_tr = X_tr[y_tr['Incident_Rate'] >= 0.5]\n",
    "y_tr = y_tr[y_tr['Incident_Rate'] >= 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    Province_State  Population  Elapsed_Days  Percentage_Home\n157       Nebraska   1934408.0             0        19.236149\n265     Washington   7614893.0             0        23.675703\n282     Washington   7614893.0             1        24.347069\n307     Washington   7614893.0             2        24.577092\n337     Washington   7614893.0             3        27.524526",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Province_State</th>\n      <th>Population</th>\n      <th>Elapsed_Days</th>\n      <th>Percentage_Home</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>157</th>\n      <td>Nebraska</td>\n      <td>1934408.0</td>\n      <td>0</td>\n      <td>19.236149</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>Washington</td>\n      <td>7614893.0</td>\n      <td>0</td>\n      <td>23.675703</td>\n    </tr>\n    <tr>\n      <th>282</th>\n      <td>Washington</td>\n      <td>7614893.0</td>\n      <td>1</td>\n      <td>24.347069</td>\n    </tr>\n    <tr>\n      <th>307</th>\n      <td>Washington</td>\n      <td>7614893.0</td>\n      <td>2</td>\n      <td>24.577092</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>Washington</td>\n      <td>7614893.0</td>\n      <td>3</td>\n      <td>27.524526</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "X_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         Population  Elapsed_Days  Percentage_Home\ncount  2.920000e+03   2920.000000      2920.000000\nmean   6.420689e+06     27.018493        37.653490\nstd    7.291724e+06     16.636420         6.623412\nmin    5.787590e+05      0.000000        17.885169\n25%    1.787065e+06     13.000000        32.934542\n50%    4.467673e+06     27.000000        37.216028\n75%    7.614893e+06     41.000000        41.818998\nmax    3.951222e+07     66.000000        69.594465",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Population</th>\n      <th>Elapsed_Days</th>\n      <th>Percentage_Home</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.920000e+03</td>\n      <td>2920.000000</td>\n      <td>2920.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>6.420689e+06</td>\n      <td>27.018493</td>\n      <td>37.653490</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7.291724e+06</td>\n      <td>16.636420</td>\n      <td>6.623412</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.787590e+05</td>\n      <td>0.000000</td>\n      <td>17.885169</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>1.787065e+06</td>\n      <td>13.000000</td>\n      <td>32.934542</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>4.467673e+06</td>\n      <td>27.000000</td>\n      <td>37.216028</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.614893e+06</td>\n      <td>41.000000</td>\n      <td>41.818998</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>3.951222e+07</td>\n      <td>66.000000</td>\n      <td>69.594465</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "X_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 2920 entries, 157 to 3572\nData columns (total 4 columns):\n #   Column           Non-Null Count  Dtype  \n---  ------           --------------  -----  \n 0   Province_State   2920 non-null   object \n 1   Population       2920 non-null   float64\n 2   Elapsed_Days     2920 non-null   int64  \n 3   Percentage_Home  2920 non-null   float64\ndtypes: float64(2), int64(1), object(1)\nmemory usage: 114.1+ KB\n"
    }
   ],
   "source": [
    "X_tr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2920, 3)\n[[27.         -0.6153619  -1.62433509 -2.78111875]\n [48.          0.16380336 -1.62433509 -2.11072188]\n [48.          0.16380336 -1.56421571 -2.00934203]\n ...\n [49.         -0.63487517  1.26139521 -0.78225105]\n [50.         -0.08205976  1.68223088 -0.54472124]\n [51.         -0.80130986  1.68223088 -0.64127019]]\n"
    }
   ],
   "source": [
    "#standardizer function which standardizes the numerical data and encodes the categorical data with LabelEncoder\n",
    "def standardize1 (X_tr):\n",
    "    #standadizing the numercial values\n",
    "    scaler = StandardScaler()\n",
    "    X = X_tr.values[:,1:4]\n",
    "    scaler.fit(X)\n",
    "    X_tr_std_num = np.asarray(scaler.transform(X)).astype(np.float64)\n",
    "\n",
    "    #standadizing the categorical values\n",
    "    encoder = LabelEncoder()\n",
    "    X = X_tr.values[:,0].reshape(-1, 1)\n",
    "    encoder.fit(X)\n",
    "    X_tr_std_cat =  encoder.transform(X).reshape(-1, 1)\n",
    "\n",
    "    return np.concatenate((X_tr_std_cat, X_tr_std_num),axis=1)\n",
    "\n",
    "X_tr_std1 = standardize1(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          1.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.         -0.6153619  -1.62433509\n  -2.78111875]\n [ 0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   1.          0.          0.          0.          0.16380336 -1.62433509\n  -2.11072188]\n [ 0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   1.          0.          0.          0.          0.16380336 -1.56421571\n  -2.00934203]\n [ 0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   1.          0.          0.          0.          0.16380336 -1.50409633\n  -1.97460725]\n [ 0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   0.          0.          0.          0.          0.          0.\n   1.          0.          0.          0.          0.16380336 -1.44397695\n  -1.5295287 ]]\n"
    }
   ],
   "source": [
    "#standardizer function which standardizes the numerical data and encodes the categorical data with one hot encoding\n",
    "def standardize2 (X_tr):\n",
    "    #standadizing the numercial values\n",
    "    scaler = StandardScaler()\n",
    "    X = X_tr.values[:,1:4]\n",
    "    scaler.fit(X)\n",
    "    X_tr_std_num = np.asarray(scaler.transform(X)).astype(np.float64)\n",
    "\n",
    "    #standadizing the categorical values\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    X = X_tr.values[:,0].reshape(-1, 1)\n",
    "    encoder.fit(X)\n",
    "    X_tr_std_cat =  encoder.transform(X)\n",
    "\n",
    "    return np.concatenate((X_tr_std_cat, X_tr_std_num),axis=1)\n",
    "\n",
    "X_tr_std2 = standardize2(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(2920, 4)\n[[27.         -0.6153619  -1.62433509 -2.78111875]\n [48.          0.16380336 -1.62433509 -2.11072188]\n [48.          0.16380336 -1.56421571 -2.00934203]\n [48.          0.16380336 -1.50409633 -1.97460725]\n [48.          0.16380336 -1.44397695 -1.5295287 ]]\n"
    }
   ],
   "source": [
    "X_tr_std = X_tr_std1\n",
    "print(X_tr_std.shape)\n",
    "print(X_tr_std[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "     Incident_Rate\n157       0.568649\n265       0.538419\n282       0.945516\n307       1.116234\n337       1.444538",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Incident_Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>157</th>\n      <td>0.568649</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>0.538419</td>\n    </tr>\n    <tr>\n      <th>282</th>\n      <td>0.945516</td>\n    </tr>\n    <tr>\n      <th>307</th>\n      <td>1.116234</td>\n    </tr>\n    <tr>\n      <th>337</th>\n      <td>1.444538</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "y_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Incident_Rate\ncount    2920.000000\nmean      139.077962\nstd       232.835254\nmin         0.503619\n25%        16.006792\n50%        60.191737\n75%       145.736850\nmax      1712.395998",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Incident_Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2920.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>139.077962</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>232.835254</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.503619</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>16.006792</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>60.191737</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>145.736850</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1712.395998</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "y_tr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 2920 entries, 157 to 3572\nData columns (total 1 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Incident_Rate  2920 non-null   float64\ndtypes: float64(1)\nmemory usage: 45.6 KB\n"
    }
   ],
   "source": [
    "y_tr.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(780, 4)\n(780, 1)\n"
    }
   ],
   "source": [
    "X_te = pd.read_csv('../data/X_te.csv')   \n",
    "y_te = pd.read_csv('../data/y_te.csv') \n",
    "print(X_te.shape)\n",
    "print(y_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(780, 3)\n"
    }
   ],
   "source": [
    "X_te = X_te[y_te['Incident_Rate'] >= 0.5]\n",
    "y_te = y_te[y_te['Incident_Rate'] >= 0.5]\n",
    "\n",
    "X_te_std1 = standardize1(X_te)\n",
    "X_te_std2 = standardize2(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(780, 4)\n[[ 0.         -0.20335228 -0.6739714  -1.28501501]\n [ 1.         -0.78022736 -0.87141654 -0.12025688]\n [ 2.          0.12514807 -0.97013911  0.66406584]\n [ 3.         -0.46407212 -0.57524883 -1.27191632]\n [ 4.          4.58255718 -0.27908111  1.09397147]]\n"
    }
   ],
   "source": [
    "X_te_std = X_te_std1\n",
    "print(X_te_std.shape)\n",
    "print(X_te_std[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       Incident_Rate\ncount     780.000000\nmean      402.180122\nstd       390.947895\nmin        42.852678\n25%       160.799613\n50%       246.760960\n75%       478.752059\nmax      1858.348711",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Incident_Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>780.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>402.180122</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>390.947895</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>42.852678</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>160.799613</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>246.760960</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>478.752059</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1858.348711</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "y_te.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designing our regression models\n",
    "\n",
    "without any delays\n",
    "\n",
    "1- Random Forests Regression\n",
    "\n",
    "2- Support Vector Machine Regression \n",
    "\n",
    "3- ANN Regression based on the negative binomial loss function and Adam Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_tr_std\n",
    "y = y_tr.values\n",
    "\n",
    "Xt = X_te_std\n",
    "yt = y_te.values\n",
    "\n",
    "X = np.asarray(X).astype(np.float64)\n",
    "y = np.asarray(y).astype(np.float64)\n",
    "Xt = np.asarray(Xt).astype(np.float64)\n",
    "yt = np.asarray(yt).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "OOB: 0.09723\nGrid: {'max_depth': 16, 'n_estimators': 10}\n"
    }
   ],
   "source": [
    "params = {\n",
    "    \"n_estimators\": [10, 50, 100, 200],\n",
    "    \"max_depth\": [4, 8, 12, 16, 20, 32, 64]\n",
    "}\n",
    "best_score = -np.Inf \n",
    "rf = RandomForestRegressor()\n",
    "for g in ParameterGrid(params):\n",
    "    rf.set_params(**g)\n",
    "    rf.fit(X, y)\n",
    "    # save if best\n",
    "    score = rf.score(Xt, yt)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_grid = g\n",
    "\n",
    "print(\"r2 score: %0.5f\" % best_score )\n",
    "print(\"Grid:\", best_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "r2 score: -0.70803\nGrid: {'C': 5, 'gamma': 'scale', 'kernel': 'linear'}\n"
    }
   ],
   "source": [
    "params = {\n",
    "    \"C\" : [0.01, 0.1, 0.2, 0.5, 1, 2, 5],\n",
    "    \"kernel\" : [\"rbf\",\"poly\",\"sigmoid\", \"linear\"],\n",
    "    \"gamma\" : [\"scale\"]\n",
    "}\n",
    "\n",
    "best_score = -np.Inf \n",
    "svm = SVR()\n",
    "for g in ParameterGrid(params):\n",
    "    svm.set_params(**g)\n",
    "    svm.fit(X, y)\n",
    "    # save if best\n",
    "    score = svm.score(Xt, yt)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_grid = g\n",
    "\n",
    "print(\"r2 score: %0.5f\" % best_score )\n",
    "print(\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Net Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(32, 4), dtype=float64, numpy=\narray([[27.        , -0.6153619 , -1.62433509, -2.78111875],\n       [48.        ,  0.16380336, -1.62433509, -2.11072188],\n       [48.        ,  0.16380336, -1.56421571, -2.00934203],\n       [48.        ,  0.16380336, -1.50409633, -1.97460725],\n       [48.        ,  0.16380336, -1.44397695, -1.5295287 ],\n       [32.        ,  1.78765747, -1.62433509, -1.36014191],\n       [48.        ,  0.16380336, -1.38385757, -0.8831    ],\n       [32.        ,  1.78765747, -1.56421571, -2.33151197],\n       [48.        ,  0.16380336, -1.32373819, -1.97009169],\n       [ 8.        , -0.78389125, -1.62433509, -1.84484238],\n       [21.        ,  0.06471654, -1.62433509, -2.30655771],\n       [32.        ,  1.78765747, -1.50409633, -2.09568061],\n       [48.        ,  0.16380336, -1.2636188 , -1.93146949],\n       [ 5.        , -0.09079692, -1.62433509, -2.2611713 ],\n       [ 8.        , -0.78389125, -1.62433509, -1.46458267],\n       [21.        ,  0.06471654, -1.56421571, -2.48916324],\n       [32.        ,  1.78765747, -1.44397695, -2.07775974],\n       [42.        , -0.75935101, -1.62433509, -2.93758857],\n       [48.        ,  0.16380336, -1.20349942, -1.93269859],\n       [ 4.        ,  4.53900928, -1.62433509, -1.89831191],\n       [ 5.        , -0.09079692, -1.56421571, -1.82863162],\n       [ 8.        , -0.78389125, -1.62433509, -1.26220615],\n       [15.        , -0.44792947, -1.62433509, -2.65069008],\n       [21.        ,  0.06471654, -1.50409633, -1.85896418],\n       [27.        , -0.6153619 , -1.62433509, -2.24548803],\n       [32.        ,  1.78765747, -1.38385757, -1.79267082],\n       [37.        , -0.30216846, -1.62433509, -1.86335906],\n       [42.        , -0.75935101, -1.56421571, -2.36258558],\n       [48.        ,  0.16380336, -1.14338004, -1.51236093],\n       [ 4.        ,  4.53900928, -1.56421571, -2.03950138],\n       [ 5.        , -0.09079692, -1.50409633, -1.82957676],\n       [ 8.        , -0.78389125, -1.62433509, -1.48528588]])>"
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((Xt, yt))\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "#no shuffle\n",
    "# train_dataset = train_dataset.shuffle(200)\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "X,y = next(iter(train_dataset))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[1 0 1]\n [1 1 0]]\n[[0.74312899 0.90220121 0.02931784]\n [0.52646074 0.89741392 0.87562621]]\n"
    }
   ],
   "source": [
    "y_true = np.random.randint(0, 2, size=(2, 3))\n",
    "print(y_true)\n",
    "y_pred = np.random.random(size=(2, 3))\n",
    "print(y_pred)\n",
    "loss = tf.keras.losses.poisson(y_true, y_pred)\n",
    "assert loss.shape == (2,)\n",
    "y_pred = y_pred + 1e-7\n",
    "assert np.allclose(\n",
    "    loss.numpy(), np.mean(y_pred - y_true * np.log(y_pred), axis=-1),\n",
    "    atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the losses the poisson loss Asuumes Mean = Variance\n",
    "loss_func = losses.Poisson()\n",
    "\n",
    "# logistic_loss = losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y, training):\n",
    "  # training=training is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  y_pred = model(x, training= training)\n",
    "\n",
    "  return loss_func(y_true= y, y_pred= y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient tape lets TF know with respect to what to take gradients inputs = X an targets = Y\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape: # getting gradient tapes for the automatix differentiation\n",
    "    loss_value = loss(model, inputs, targets, training=True)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_10 (Dense)             (None, 30)                150       \n_________________________________________________________________\ndense_11 (Dense)             (None, 1)                 31        \n=================================================================\nTotal params: 181\nTrainable params: 181\nNon-trainable params: 0\n_________________________________________________________________\nNone\ntf.Tensor(nan, shape=(), dtype=float64)\n"
    }
   ],
   "source": [
    "# the first model with relu activation function and 3 units in the hidden layer\n",
    "model = Sequential([\n",
    "  layers.Dense(30, input_dim = 4, activation=\"relu\"), \n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "y_pred = model(X)\n",
    "print(model.summary())\n",
    "\n",
    "print(loss(model, X, y, training= False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'log'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-4715e8ff6e3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;31m# create the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;31m# last term can be avoided since it doesn't depend on y_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# however keeping it gives a nice lower bound to zero\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'log'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def gen_data(N = 10000):\n",
    "    data = np.random.uniform(-1, 1, (N, 3))\n",
    "    data = sm.add_constant(data)\n",
    "    data = pd.DataFrame(data, columns = ['intercept', 'Var1', 'Var2', 'Var3'])\n",
    "    lam = np.exp(-2*data['intercept'] + data['Var1'] - 0.5*data['Var2'] + 0.3*data['Var3'] )\n",
    "    resp = np.random.poisson(lam = lam)\n",
    "    data['lam'] = lam\n",
    "    data['response'] = resp\n",
    "    return data\n",
    "\n",
    "dtrain = gen_data()\n",
    "dtrain.drop('lam', axis=1)\n",
    "\n",
    "X = tf.constant(dtrain[['intercept', 'Var1', 'Var2', 'Var3']].values, name = 'X', dtype=tf.float32)\n",
    "# <tf.Tensor 'X:0' shape=(10000, 4) dtype=float32>\n",
    "\n",
    "y = tf.constant(value = list(dtrain['response']), dtype = tf.float32, name='y', shape=(dtrain.shape[0], 1))\n",
    "# <tf.Tensor 'y:0' shape=(10000, 1) dtype=float32>\n",
    "\n",
    "parameters = tf.Variable(tf.zeros([4, 1])) #Initial Values\n",
    "# <tf.Variable 'Variable:0' shape=(4, 1) dtype=float32_ref>\n",
    "\n",
    "logits = tf.matmul(X, parameters, name=\"logits\")\n",
    "# <tf.Tensor 'logits:0' shape=(10000, 1) dtype=float32> \n",
    "\n",
    "y_hat = tf.exp(logits)\n",
    "\n",
    "# create the loss\n",
    "loss = tf.reduce_mean(-y*tf.log(y_hat)+y_hat)\n",
    "# last term can be avoided since it doesn't depend on y_pred\n",
    "# however keeping it gives a nice lower bound to zero\n",
    "# tf.lgamma computes the log of the absolute value of Gamma(x) element-wise\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "n_epochs = 10000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        if epoch % 100 == 0:\n",
    "            print(\"Epoch\", epoch, \"Loss = \", loss.eval())\n",
    "    best_parameters = parameters.eval()\n",
    "    \n",
    "print(best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('stat4': conda)",
   "language": "python",
   "name": "python37764bitstat4condab58549248af542fb9fba1912e8e0dde7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}